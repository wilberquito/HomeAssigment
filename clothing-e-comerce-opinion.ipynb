{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets origin from kaggle, check out [here](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews).\n",
    "\n",
    "This dataset includes 23486 rows and 10 feature variables. Each row corresponds to a customer review, and includes the variables:\n",
    "\n",
    "- **Clothing ID**: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "- **Age**: Positive Integer variable of the reviewers age.\n",
    "- **Title**: String variable for the title of the review.\n",
    "- **Review Text**: String variable for the review body.\n",
    "- **Rating**: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.\n",
    "- **Recommended IND**: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended.\n",
    "- **Positive Feedback Count**: Positive Integer documenting the number of other customers who found this review positive.\n",
    "- **Division Name**: Categorical name of the product high level division.\n",
    "- **Department Name**: Categorical name of the product department name.\n",
    "- **Class Name**: Categorical name of the product class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>positive feedback count</th>\n",
       "      <th>division name</th>\n",
       "      <th>department name</th>\n",
       "      <th>class name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id  age                    title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   positive feedback count   division name department name class name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"./Womens Clothing E-Commerce Reviews.csv\"\n",
    "cols = pd.read_csv(dataset_name, nrows=1).columns\n",
    "reviews_df = pd.read_csv(dataset_name, usecols=cols[1:])\n",
    "cols = [col.lower() for col in reviews_df.columns]\n",
    "reviews_df.columns = cols\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>positive feedback count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "      <td>23486.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>918.118709</td>\n",
       "      <td>43.198544</td>\n",
       "      <td>4.196032</td>\n",
       "      <td>0.822362</td>\n",
       "      <td>2.535936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>203.298980</td>\n",
       "      <td>12.279544</td>\n",
       "      <td>1.110031</td>\n",
       "      <td>0.382216</td>\n",
       "      <td>5.702202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clothing id           age        rating  recommended ind  \\\n",
       "count  23486.000000  23486.000000  23486.000000     23486.000000   \n",
       "mean     918.118709     43.198544      4.196032         0.822362   \n",
       "std      203.298980     12.279544      1.110031         0.382216   \n",
       "min        0.000000     18.000000      1.000000         0.000000   \n",
       "25%      861.000000     34.000000      4.000000         1.000000   \n",
       "50%      936.000000     41.000000      5.000000         1.000000   \n",
       "75%     1078.000000     52.000000      5.000000         1.000000   \n",
       "max     1205.000000     99.000000      5.000000         1.000000   \n",
       "\n",
       "       positive feedback count  \n",
       "count             23486.000000  \n",
       "mean                  2.535936  \n",
       "std                   5.702202  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   3.000000  \n",
       "max                 122.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 10 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   clothing id              23486 non-null  int64 \n",
      " 1   age                      23486 non-null  int64 \n",
      " 2   title                    19676 non-null  object\n",
      " 3   review text              22641 non-null  object\n",
      " 4   rating                   23486 non-null  int64 \n",
      " 5   recommended ind          23486 non-null  int64 \n",
      " 6   positive feedback count  23486 non-null  int64 \n",
      " 7   division name            23472 non-null  object\n",
      " 8   department name          23472 non-null  object\n",
      " 9   class name               23472 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    13131\n",
       "4     5077\n",
       "3     2871\n",
       "2     1565\n",
       "1      842\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = reviews_df[\"rating\"].plot(kind=\"hist\", bins=np.arange(0, 6) + 0.5, ec='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>positive feedback count</th>\n",
       "      <th>division name</th>\n",
       "      <th>department name</th>\n",
       "      <th>class name</th>\n",
       "      <th>soft rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id  age                    title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   positive feedback count   division name department name class name  \\\n",
       "0                        0       Initmates        Intimate  Intimates   \n",
       "1                        4         General         Dresses    Dresses   \n",
       "2                        0         General         Dresses    Dresses   \n",
       "3                        0  General Petite         Bottoms      Pants   \n",
       "4                        6         General            Tops    Blouses   \n",
       "\n",
       "   soft rating  \n",
       "0            2  \n",
       "1            3  \n",
       "2            1  \n",
       "3            3  \n",
       "4            3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def soft_rating(rating):\n",
    "    new_rating = 3\n",
    "    if rating <= 3:\n",
    "        new_rating = 1\n",
    "    elif rating <= 4:\n",
    "        new_rating = 2\n",
    "    return new_rating\n",
    "\n",
    "\n",
    "reviews_df[\"soft rating\"] = reviews_df[\"rating\"].map(soft_rating)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "soft rating\n",
       "3    13131\n",
       "1     5278\n",
       "2     5077\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"soft rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = reviews_df[\"soft rating\"].plot(kind=\"hist\", bins=np.arange(0, 4) + 0.5, ec=\"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing not usuful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>positive feedback count</th>\n",
       "      <th>soft rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.030622</td>\n",
       "      <td>0.043079</td>\n",
       "      <td>0.036042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <td>0.026831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792336</td>\n",
       "      <td>-0.064961</td>\n",
       "      <td>0.941389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommended ind</th>\n",
       "      <td>0.030622</td>\n",
       "      <td>0.792336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069045</td>\n",
       "      <td>0.726893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive feedback count</th>\n",
       "      <td>0.043079</td>\n",
       "      <td>-0.064961</td>\n",
       "      <td>-0.069045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soft rating</th>\n",
       "      <td>0.036042</td>\n",
       "      <td>0.941389</td>\n",
       "      <td>0.726893</td>\n",
       "      <td>-0.062530</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              age    rating  recommended ind  \\\n",
       "age                      1.000000  0.026831         0.030622   \n",
       "rating                   0.026831  1.000000         0.792336   \n",
       "recommended ind          0.030622  0.792336         1.000000   \n",
       "positive feedback count  0.043079 -0.064961        -0.069045   \n",
       "soft rating              0.036042  0.941389         0.726893   \n",
       "\n",
       "                         positive feedback count  soft rating  \n",
       "age                                     0.043079     0.036042  \n",
       "rating                                 -0.064961     0.941389  \n",
       "recommended ind                        -0.069045     0.726893  \n",
       "positive feedback count                 1.000000    -0.062530  \n",
       "soft rating                            -0.062530     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_reviews_df = reviews_df.select_dtypes(include=\"number\").drop(\n",
    "    labels=[\"clothing id\"], axis=1\n",
    ")\n",
    "numeric_reviews_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this information it is pretty clear that `positive feedback count` bothers more than helps.\n",
    "And not only that but it is a feature that doesn't really talk about the user opinion but \n",
    "how other interpreted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>division name</th>\n",
       "      <th>department name</th>\n",
       "      <th>class name</th>\n",
       "      <th>soft rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id  age                    title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "\n",
       "  division name department name class name  soft rating  \n",
       "0     Initmates        Intimate  Intimates            2  \n",
       "1       General         Dresses    Dresses            3  \n",
       "2       General         Dresses    Dresses            1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = reviews_df.drop(labels=[\"positive feedback count\"], axis=1)\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "division name\n",
       "General           13850\n",
       "General Petite     8120\n",
       "Initmates          1502\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['division name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department name\n",
       "Tops        10468\n",
       "Dresses      6319\n",
       "Bottoms      3799\n",
       "Intimate     1735\n",
       "Jackets      1032\n",
       "Trend         119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['department name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class name\n",
       "Dresses           6319\n",
       "Knits             4843\n",
       "Blouses           3097\n",
       "Sweaters          1428\n",
       "Pants             1388\n",
       "Jeans             1147\n",
       "Fine gauge        1100\n",
       "Skirts             945\n",
       "Jackets            704\n",
       "Lounge             691\n",
       "Swim               350\n",
       "Outerwear          328\n",
       "Shorts             317\n",
       "Sleep              228\n",
       "Legwear            165\n",
       "Intimates          154\n",
       "Layering           146\n",
       "Trend              119\n",
       "Casual bottoms       2\n",
       "Chemises             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['class name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decide to drop the features above because they are not balanced at all and to make things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>soft rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id  age                    title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "\n",
       "   soft rating  \n",
       "0            2  \n",
       "1            3  \n",
       "2            1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = reviews_df.drop(labels=['division name', 'department name', 'class name'], axis=1, errors='ignore')\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 15., 25., 35., 45., 55., 65., 75., 85., 95.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = 10\n",
    "spam_window = spam / 2\n",
    "limit = int(100 / spam)\n",
    "bins = np.array([x*spam for x in range(limit)]) + spam_window\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,  892, 5175, 7771, 5110, 3152, 1193,  161,   30]),\n",
       " array([ 5., 15., 25., 35., 45., 55., 65., 75., 85., 95.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(reviews_df['age'], bins = bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_df['age'].plot(kind='hist', bins=bins, ec='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>soft rating</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id  age                    title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "\n",
       "   soft rating  generation  \n",
       "0            2           1  \n",
       "1            3           1  \n",
       "2            1           3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def soft_age(age):\n",
    "    generation = 3\n",
    "    if age < 35:\n",
    "        generation = 1\n",
    "    elif age < 55:\n",
    "        generation = 2\n",
    "    return generation\n",
    "\n",
    "reviews_df['generation'] = reviews_df['age'].map(soft_age)\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation\n",
       "2    12881\n",
       "1     6067\n",
       "3     4538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['generation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clothing id        False\n",
       "age                False\n",
       "title               True\n",
       "review text         True\n",
       "rating             False\n",
       "recommended ind    False\n",
       "soft rating        False\n",
       "generation         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aham, there are some missing values. Let's figure it out how many for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clothing id           0\n",
       "age                   0\n",
       "title              3810\n",
       "review text         845\n",
       "rating                0\n",
       "recommended ind       0\n",
       "soft rating           0\n",
       "generation            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, what about the % of missing values to respect the hole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clothing id         0.000000\n",
       "age                 0.000000\n",
       "title              16.222430\n",
       "review text         3.597888\n",
       "rating              0.000000\n",
       "recommended ind     0.000000\n",
       "soft rating         0.000000\n",
       "generation          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reviews_df.isna().sum() * 100) / reviews_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What it bothers me the most if the 16% of missing values for titles.\n",
    "But there is arround 3.6% of missing descriptions which are the big problems.\n",
    "Titles can be generated as resume from the description but not the other way arround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>clothing id</th>\n",
       "      <th>age</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>soft rating</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  clothing id  age                    title  \\\n",
       "0      0          767   33                      NaN   \n",
       "1      1         1080   34                      NaN   \n",
       "2      2         1077   60  Some major design flaws   \n",
       "\n",
       "                                         review text  rating  recommended ind  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "\n",
       "   soft rating  generation  \n",
       "0            2           1  \n",
       "1            3           1  \n",
       "2            1           3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = reviews_df[~reviews_df['review text'].isna()]\n",
    "reviews_df = reviews_df.reset_index()\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        NaN\n",
       "1                        NaN\n",
       "2    Some major design flaws\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df['title'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clothing id</th>\n",
       "      <th>title</th>\n",
       "      <th>review text</th>\n",
       "      <th>soft rating</th>\n",
       "      <th>recommended ind</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clothing id                    title  \\\n",
       "0          767                      NaN   \n",
       "1         1080                      NaN   \n",
       "2         1077  Some major design flaws   \n",
       "\n",
       "                                         review text soft rating  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...           2   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...           3   \n",
       "2  I had such high hopes for this dress and reall...           1   \n",
       "\n",
       "   recommended ind generation  \n",
       "0                1          1  \n",
       "1                1          1  \n",
       "2                0          3  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    'clothing id',\n",
    "    'title',\n",
    "    'review text',\n",
    "    'soft rating',\n",
    "    'recommended ind',\n",
    "    'generation'\n",
    "]\n",
    "\n",
    "reviews_df['soft rating'] = reviews_df['soft rating'].astype('category')\n",
    "reviews_df['generation'] = reviews_df['generation'].astype('category')\n",
    "\n",
    "reviews_df = reviews_df[features]\n",
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clothing id           int64\n",
       "title                object\n",
       "review text          object\n",
       "soft rating        category\n",
       "recommended ind       int64\n",
       "generation         category\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate summaries from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilberquito/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['clothing id', 'title', 'review text', 'soft rating', 'recommended ind', 'generation', '__index_level_0__'],\n",
       "         num_rows: 15740\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['clothing id', 'title', 'review text', 'soft rating', 'recommended ind', 'generation', '__index_level_0__'],\n",
       "         num_rows: 3935\n",
       "     })\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['clothing id', 'title', 'review text', 'soft rating', 'recommended ind', 'generation', '__index_level_0__'],\n",
       "     num_rows: 2966\n",
       " }))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def generate_datasets(reviews, test_size=0.2, stratify='soft rating'):\n",
    "\n",
    "    titled_reviews = reviews[~reviews['title'].isna()]\n",
    "    infer_reviews = reviews[reviews['title'].isna()]\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        titled_reviews, test_size=test_size, stratify=titled_reviews[stratify])\n",
    "    \n",
    "\n",
    "    datasets = [Dataset.from_pandas(df) for df in [train, test, infer_reviews]]\n",
    "    dataset_names = ['train', 'test', 'infer']\n",
    "    \n",
    "    dict_datasets = dict(zip(dataset_names, datasets))\n",
    "\n",
    "    train_datasets = DatasetDict(\n",
    "        {\n",
    "            'train': dict_datasets['train'],\n",
    "            'test': dict_datasets['test']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    infer_dataset = dict_datasets['infer']\n",
    "\n",
    "    return train_datasets, infer_dataset\n",
    "\n",
    "\n",
    "train_datasets, infer_dataset = generate_datasets(reviews_df)\n",
    "train_datasets, infer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"review text\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=1024, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"title\"],\n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 15740/15740 [00:06<00:00, 2621.87 examples/s]\n",
      "Map: 100%|| 3935/3935 [00:01<00:00, 2629.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "batched = True\n",
    "train_datasets = train_datasets.map(preprocess_function, batch_size=batch_size, batched=batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6088907406813884"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_info = torch.cuda.mem_get_info()\n",
    "mem_info[0] * 100 / mem_info[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wilberquito/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 32.69 MiB is free. Process 16797 has 2.43 GiB memory in use. Including non-PyTorch memory, this process has 454.00 MiB memory in use. Of the allocated memory 380.07 MiB is allocated by PyTorch, and 5.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 30\u001b[0m\n\u001b[1;32m      6\u001b[0m training_args \u001b[38;5;241m=\u001b[39m Seq2SeqTrainingArguments(\n\u001b[1;32m      7\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawesome_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     eval_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     22\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1702\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;66;03m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1702\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1712\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1713\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1714\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1715\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1716\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:686\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    684\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    696\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:535\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    533\u001b[0m         position_bias\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     position_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# if key and values are already calculated\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m# we want only the last query position bias\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/sentimental-analysis/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:434\u001b[0m, in \u001b[0;36mT5Attention.compute_bias\u001b[0;34m(self, query_length, key_length, device)\u001b[0m\n\u001b[1;32m    432\u001b[0m context_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(query_length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    433\u001b[0m memory_position \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(key_length, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m--> 434\u001b[0m relative_position \u001b[38;5;241m=\u001b[39m \u001b[43mmemory_position\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontext_position\u001b[49m  \u001b[38;5;66;03m# shape (query_length, key_length)\u001b[39;00m\n\u001b[1;32m    435\u001b[0m relative_position_bucket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_position_bucket(\n\u001b[1;32m    436\u001b[0m     relative_position,  \u001b[38;5;66;03m# shape (query_length, key_length)\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     bidirectional\u001b[38;5;241m=\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder),\n\u001b[1;32m    438\u001b[0m     num_buckets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention_num_buckets,\n\u001b[1;32m    439\u001b[0m     max_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention_max_distance,\n\u001b[1;32m    440\u001b[0m )\n\u001b[1;32m    441\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention_bias(relative_position_bucket)  \u001b[38;5;66;03m# shape (query_length, key_length, num_heads)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 3.81 GiB of which 32.69 MiB is free. Process 16797 has 2.43 GiB memory in use. Including non-PyTorch memory, this process has 454.00 MiB memory in use. Of the allocated memory 380.07 MiB is allocated by PyTorch, and 5.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "epochs = 5\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"awesome_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=weight_decay,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=epochs,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_datasets[\"train\"],\n",
    "    eval_dataset=train_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
